import gradio as gr
from TTS.api import TTS

tts = TTS("tts_models/multilingual/multi-dataset/xtts_v1")
tts.to("cuda")


def predict(prompt, language, audio_file_pth, agree):
    if agree == True:
        tts.tts_to_file(
            text=prompt,
            file_path="output.wav",
            speaker_wav=audio_file_pth,
            language=language_mapping.get(language, "Desconocido"),
        )

        return (
            gr.make_waveform(
                audio="output.wav",
            ),
            "output.wav",
        )
    else:
        gr.Warning("Please accept the Terms & Condition!")


title = """Coquiüê∏ XTTS <a href="https://www.youtube.com/channel/UC1ejkTHsiq8aQAeYIZyIyeg">Visita mi Canal: IA (Sistema de interes)</a>"""

description = """
<a href="https://huggingface.co/coqui/XTTS-v1">XTTS</a> es un modelo de generaci√≥n de voz que te permite clonar voces en diferentes idiomas usando solo un clip de audio r√°pido de 3 segundos. 
<br/>
XTTS se basa en investigaciones anteriores, como Tortoise, con innovaciones arquitect√≥nicas adicionales y capacitaci√≥n para hacer posible la clonaci√≥n de voz en varios idiomas y la generaci√≥n de voz multiling√ºe.
<br/>
Este es el mismo modelo que impulsa nuestra aplicaci√≥n creadora <a href="https://coqui.ai">Coqui Studio</a>, as√≠ como <a href="https://docs.coqui.ai"> API Coqui</a>. En producci√≥n aplicamos modificaciones para hacer posible la transmisi√≥n de baja latencia.
<br/>
Deje una estrella en Github <a href="https://github.com/coqui-ai/TTS">üê∏TTS</a>, donde reside nuestro c√≥digo de entrenamiento e inferencia de c√≥digo abierto.
<br/>
<p>Para una inferencia m√°s r√°pida sin esperar en la cola, debe duplicar este espacio y actualizar a GPU a trav√©s de la configuraci√≥n.
<br/>
<a href="https://huggingface.co/spaces/coqui/xtts?duplicate=true">
<img style="margin-top: 0em; margin-bottom: 0em" src="https://bit.ly/3gLdBN6" alt="Duplicate Space"></a>
</p>
"""

article = """
<div style='margin:20px auto;'>
<p>Al utilizar esta demostraci√≥n, acepta los t√©rminos de la Licencia de modelo p√∫blico de Coqui en https://coqui.ai/cpml</p>
</div>
"""

language_mapping = {
    'English': 'en',
    'Spanish': 'es',
    'French': 'fr',
    'German': 'de',
    'Italian': 'it',
    'Portuguese': 'pt',
    'Polish': 'pl',
    'Turkish': 'tr',
    'Russian': 'ru',
    'Dutch': 'nl',
    'Czech': 'cs',
    'Arabic': 'ar',
    'Chinese (Simplified)': 'zh'
}

gr.Interface(
    fn=predict,
    inputs=[
        gr.Textbox(
            label="Text Prompt",
            info="One or two sentences at a time is better",
            value="It took me quite a long time to develop a voice, and now that I have it I'm not going to be silent.",
        ),
        gr.Dropdown(
            label="Language",
            info="Select an output language for the synthesised speech",
            choices=[
                "Arabic",
                "Chinese (Simplified)",
                "Czech",
                "Dutch",
                "English",
                "French",
                "German",
                "Italian",
                "Polish",
                "Portuguese",
                "Russian",
                "Spanish",
                "Turkish",
            ],
            max_choices=1,
            value="en",
        ),
        gr.Audio(
            label="Reference Audio",
            info="Click on the ‚úé button to upload your own target speaker audio",
            type="filepath",
            value="examples/female.wav",
        ),
        gr.Checkbox(
            label="Agree",
            value=False,
            info="I agree to the terms of the Coqui Public Model License at https://coqui.ai/cpml",
        ),
    ],
    outputs=[
        gr.Video(label="Waveform Visual"),
        gr.Audio(label="Synthesised Audio"),
    ],
    title=title,
    description=description,
    article=article,
    examples="",
).queue().launch(share=True)
